{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "30th July - Optimal Clusters",
      "provenance": [],
      "collapsed_sections": [
        "Us6xVpclRb_A",
        "Ly1lLTEs0yxu",
        "unpMyGpN01AE",
        "hwTqc9CP_DWF",
        "Kky74E1-V67I"
      ],
      "toc_visible": true,
      "mount_file_id": "1XQiLyjIhVdgtFhuzVLHo5QTOzMLa85lV",
      "authorship_tag": "ABX9TyMPCh5AuhqmlFETGmBPmY/e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shengy90/MSc-Project/blob/master/notebooks/30th_July_Optimal_Clusters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svsqrk45tb_B",
        "colab_type": "text"
      },
      "source": [
        "# **1Ô∏è‚É£ Setup Notebook üíª**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eJpHGVpGuji",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### **Authenticate with BigQuery ‚òÅÔ∏è**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkaOt64QmU90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade google-cloud-bigquery[bqstorage,pandas]\n",
        "!pip install --upgrade pandas-gbq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6y1_cKZGJ1C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8f4aac7-4820-465e-fbcf-2cbc91d04308"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authenticated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cPJ-kLQGQ0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc df --use_bqstorage_api\n",
        "SELECT \n",
        "  COUNT(*) as total_rows\n",
        "FROM `machine-learning-msc.low_carbon_london.household_consumption_daily_agg` "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts6qMG3PGlUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "6a22653e-08e0-4eac-a6d2-1dbdc7208169"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_rows</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14841792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   total_rows\n",
              "0    14841792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4sbx8kLH89t",
        "colab_type": "text"
      },
      "source": [
        "### **Importing Libraries‚è¨**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmVtQy38Ozr6",
        "colab_type": "text"
      },
      "source": [
        "##### Standard Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0JiDvCG3U4F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c8d4eec7-891a-4588-92a9-063fadf937a9"
      },
      "source": [
        "!pip install fbprophet\n",
        "!pip install MiniSom"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fbprophet in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: Cython>=0.22 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (0.29.21)\n",
            "Requirement already satisfied: cmdstanpy==0.4 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (0.4.0)\n",
            "Requirement already satisfied: pystan>=2.14 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (2.19.1.1)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (1.0.5)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (3.2.2)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (0.0.9)\n",
            "Requirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (2.2.1)\n",
            "Requirement already satisfied: holidays>=0.9.5 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (0.9.12)\n",
            "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->fbprophet) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->fbprophet) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->fbprophet) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->fbprophet) (1.2.0)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.6/dist-packages (from LunarCalendar>=0.0.9->fbprophet) (3.7.7.1)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.6 in /usr/local/lib/python3.6/dist-packages (from convertdate>=2.1.2->fbprophet) (0.3.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from holidays>=0.9.5->fbprophet) (1.15.0)\n",
            "Requirement already satisfied: MiniSom in /usr/local/lib/python3.6/dist-packages (2.2.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr9vUfxAICRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "95e0b050-944f-41cc-d647-c5c281118d46"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import random\n",
        "import datetime as dt\n",
        "\n",
        "from minisom import MiniSom\n",
        "from tqdm import tqdm\n",
        "from datetime import date\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        " \n",
        "sns.set()\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQE0xrL4JT4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas_gbq\n",
        "def output_to_bq(forecast, table_id, project_id='machine-learning-msc'):\n",
        "    pandas_gbq.to_gbq(forecast, table_id, project_id=project_id, if_exists='append')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq2GQCXqO2ZD",
        "colab_type": "text"
      },
      "source": [
        "##### Import Github Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw_bhwfTY7U1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a5972957-2b6f-4a2b-c62d-8407bcc0c025"
      },
      "source": [
        "%cd /content\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "adc.json  mscproj  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtzIWQvBPESj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a3b75ac4-091d-43af-9b8f-ecf3f7df05b4"
      },
      "source": [
        "!rm -rf mscproj\n",
        "!git clone https://github.com/shengy90/MSc-Project mscproj\n",
        "!git pull\n",
        "%cd /content/mscproj/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mscproj'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 377 (delta 5), reused 8 (delta 4), pack-reused 361\u001b[K\n",
            "Receiving objects: 100% (377/377), 10.94 MiB | 26.06 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "/content/mscproj\n",
            "bin\t     __init__.py  notebooks  requirements.txt  sql\n",
            "definitions  Makefile\t  README.md  run.py\t       src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnq6lOTUXbat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload \n",
        "%autoreload 2 \n",
        "from src.train_prophet import TrainProphet\n",
        "from src.train_clusters import TrainClusters\n",
        "from src.train_clusters import Normaliser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uICiUW0YyfAZ",
        "colab_type": "text"
      },
      "source": [
        "# 2Ô∏è‚É£ **Generate SOM clusters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us6xVpclRb_A",
        "colab_type": "text"
      },
      "source": [
        "### **Downloading Data from BQ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VfmGhaSz4s4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc df_test --use_bqstorage_api\n",
        "WITH stg1 AS (\n",
        "SELECT \n",
        "lcl_id,\n",
        "IF(acorn_grouped = \"Adversity\", 1, 0) AS adversity,\n",
        "IF(acorn_grouped = \"Affluent\", 1, 0) AS affluent,\n",
        "IF(acorn_grouped = \"Comfortable\", 1, 0) AS comfortable,\n",
        "FORMAT_DATETIME(\"%B\", DATETIME(ts)) AS month_name,\n",
        "dayofweek,\n",
        "hhourly_rank,\n",
        "ROUND(AVG(kwhh),4) AS hh_avg,\n",
        "ROUND(MAX(kwhh),4) AS hh_max,\n",
        "ROUND(MIN(kwhh),4) AS hh_min,\n",
        "ROUND(STDDEV(kwhh),4) AS hh_stddev\n",
        "\n",
        "FROM `machine-learning-msc.forecasting_20200719.test_set`\n",
        "WHERE train_test_split = 'test'\n",
        "AND ts >= '2012-11-01' AND ts < '2013-03-01'\n",
        "\n",
        "GROUP BY 1,2,3,4,5,6,7\n",
        ")\n",
        "\n",
        "SELECT \n",
        "*,\n",
        "ROW_NUMBER() OVER (PARTITION BY lcl_id, month_name ORDER BY dayofweek ASC, hhourly_rank ASC) AS weekly_rank\n",
        "FROM stg1 \n",
        "ORDER BY lcl_id, month_name, weekly_rank, hhourly_rank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAKqRE4AIKRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc df_train --use_bqstorage_api\n",
        "WITH stg1 AS (\n",
        "SELECT \n",
        "lcl_id,\n",
        "IF(acorn_grouped = \"Adversity\", 1, 0) AS adversity,\n",
        "IF(acorn_grouped = \"Affluent\", 1, 0) AS affluent,\n",
        "IF(acorn_grouped = \"Comfortable\", 1, 0) AS comfortable,\n",
        "FORMAT_DATETIME(\"%B\", DATETIME(ts)) AS month_name,\n",
        "dayofweek,\n",
        "hhourly_rank,\n",
        "ROUND(AVG(kwhh),4) AS hh_avg,\n",
        "ROUND(MAX(kwhh),4) AS hh_max,\n",
        "ROUND(MIN(kwhh),4) AS hh_min,\n",
        "ROUND(STDDEV(kwhh),4) AS hh_stddev\n",
        "\n",
        "FROM `machine-learning-msc.forecasting_20200719.train_set`\n",
        "WHERE train_test_split = 'train'\n",
        "AND ts >= '2012-11-01' AND ts < '2013-03-01'\n",
        "\n",
        "GROUP BY 1,2,3,4,5,6,7\n",
        ")\n",
        "\n",
        "SELECT \n",
        "*,\n",
        "ROW_NUMBER() OVER (PARTITION BY lcl_id, month_name ORDER BY dayofweek ASC, hhourly_rank ASC) AS weekly_rank\n",
        "FROM stg1 \n",
        "ORDER BY lcl_id, month_name, weekly_rank, hhourly_rank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly1lLTEs0yxu",
        "colab_type": "text"
      },
      "source": [
        "### **Normalise Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNhVyPMcyjAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value_list = ['hh_avg']\n",
        "column_list = ['month_name', 'weekly_rank']\n",
        "normaliser = Normaliser(value_list, column_list)\n",
        "norm_df_train = normaliser.fit(df_train)\n",
        "norm_df_test = normaliser.predict(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unpMyGpN01AE",
        "colab_type": "text"
      },
      "source": [
        "### **Train SOM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUaW1PJi0wfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e99ed3a0-d720-4c4e-afd1-41c02378a080"
      },
      "source": [
        "for i in range(9):\n",
        "    cluster_num = i+1\n",
        "    print(f\"Training {cluster_num} clusters....\")\n",
        "    som_cluster = TrainClusters(cluster_type=\"som\")\n",
        "    som_cluster.fit(norm_df_train, cluster_num=cluster_num, sigma=0.1, learning_rate=0.1)  \n",
        "\n",
        "    train_pred = som_cluster.predict(norm_df_train)\n",
        "    test_pred = som_cluster.predict(norm_df_test)\n",
        "\n",
        "    train_pred['train_test_split'] = \"train\"\n",
        "    test_pred['train_test_split'] = \"test\"\n",
        "\n",
        "    som_results = pd.concat([train_pred[['lcl_id','cluster','train_test_split']], test_pred[['lcl_id','cluster','train_test_split']]])\n",
        "    som_results['num_clusters'] = cluster_num\n",
        "    som_results['cluster_type'] = 'som'\n",
        "\n",
        "    # output_to_bq(som_results, 'clusters_20200739.clusters')\n",
        "    print(\"Upload to BQ completed! üéâ\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 1 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 28.62229932330481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/minisom.py:511: UserWarning:\n",
            "\n",
            "The topographic error is not defined for a 1-by-1 map.\n",
            "\n",
            "2681it [00:01, 2186.75it/s]\n",
            "1000it [00:00, 2354.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 2 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 24.530185802382075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2167.18it/s]\n",
            "1000it [00:00, 2260.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 3 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 21.59310210230596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2116.74it/s]\n",
            "1000it [00:00, 2286.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 4 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 21.062202682086788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2089.48it/s]\n",
            "1000it [00:00, 2179.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 5 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " quantization error: 19.841573891542318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2130.59it/s]\n",
            "1000it [00:00, 2213.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 6 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 19.49002343512572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2100.44it/s]\n",
            "1000it [00:00, 2031.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 7 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " quantization error: 18.918113461647287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 1656.47it/s]\n",
            "1000it [00:00, 2094.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 8 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " quantization error: 18.75056029192445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2049.31it/s]\n",
            "1000it [00:00, 2136.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 9 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 18.623579866826525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2037.97it/s]\n",
            "1000it [00:00, 2116.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwTqc9CP_DWF",
        "colab_type": "text"
      },
      "source": [
        "### **Train Agglomerative Clusters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTR9D7sm_F6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "bed4f32f-1537-4a36-bf81-918dc7212b36"
      },
      "source": [
        "for i in range(9):\n",
        "    cluster_num = i+1\n",
        "    print(f\"Training {cluster_num} clusters....\")\n",
        "    agglo_cluster = TrainClusters(cluster_type=\"agglo\")\n",
        "    agglo_cluster.fit(norm_df_train, cluster_num=cluster_num)\n",
        "\n",
        "    train_pred = agglo_cluster.predict(norm_df_train)\n",
        "    test_pred = agglo_cluster.predict(norm_df_test)\n",
        "\n",
        "    train_pred['train_test_split'] = \"train\"\n",
        "    test_pred['train_test_split'] = \"test\"\n",
        "    \n",
        "    agglo_results = pd.concat([train_pred[['lcl_id','cluster','train_test_split']], test_pred[['lcl_id','cluster','train_test_split']]])\n",
        "    agglo_results['cluster'] = agglo_results['cluster'].astype(float)\n",
        "    agglo_results['num_clusters'] = cluster_num\n",
        "    agglo_results['cluster_type'] = 'agglo'\n",
        "\n",
        "    output_to_bq(agglo_results, 'clusters_20200739.clusters')\n",
        "    print(\"Upload to BQ completed! üéâ\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 1 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:02,  2.84s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 2 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:03,  3.92s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 3 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:03,  3.44s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 4 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:04,  4.55s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 5 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:02,  2.76s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 6 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:03,  3.39s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 7 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:02,  2.81s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 8 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:06,  6.57s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 9 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:03,  3.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQMQ6kACRtgv",
        "colab_type": "text"
      },
      "source": [
        "# **3Ô∏è‚É£ Forecasting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hNFBIouR0tx",
        "colab_type": "text"
      },
      "source": [
        "### **Downloading Data from BQ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iI2320mRx7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc df_train --use_bqstorage_api\n",
        "SELECT \n",
        "train.lcl_id,\n",
        "train.ts AS ds,\n",
        "train.kwhh AS y,\n",
        "weather.air_temperature\n",
        "\n",
        "FROM `machine-learning-msc.forecasting_20200719.train_set` train \n",
        "LEFT JOIN `machine-learning-msc.london_heathrow_hourly_weather_data.london_heathrow_hourly_weather` weather \n",
        "  ON TIMESTAMP_TRUNC(weather.ts, HOUR) = TIMESTAMP_TRUNC(train.ts, hour)\n",
        "  \n",
        "\n",
        "WHERE train.ts >= '2012-11-01' AND train.ts < '2013-03-01'\n",
        "ORDER BY 1,2 ASC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph4St_mDUcKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc df_test --use_bqstorage_api\n",
        "SELECT \n",
        "train.lcl_id,\n",
        "train.ts AS ds,\n",
        "train.kwhh AS y,\n",
        "weather.air_temperature\n",
        "\n",
        "FROM `machine-learning-msc.forecasting_20200719.test_set` train \n",
        "LEFT JOIN `machine-learning-msc.london_heathrow_hourly_weather_data.london_heathrow_hourly_weather` weather \n",
        "  ON TIMESTAMP_TRUNC(weather.ts, HOUR) = TIMESTAMP_TRUNC(train.ts, hour)\n",
        "  \n",
        "\n",
        "WHERE train.ts >= '2012-11-01' AND train.ts < '2013-03-01'\n",
        "ORDER BY 1,2 ASC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZQgpcwMUk2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db65bd5d-7e5f-4ac1-a028-666bbab1f40e"
      },
      "source": [
        "df_train['ds'] = df_train['ds'].dt.tz_localize(None) # remove timezones \n",
        "df_test['ds'] = df_test['ds'].dt.tz_localize(None) # remove timezones \n",
        "\n",
        "print(df_train.shape, df_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15439123, 4) (5758620, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7DdLHFDUmVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc clusters --use_bqstorage_api\n",
        "SELECT * FROM `machine-learning-msc.clusters_20200739.clusters`"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7kHACW-Vhzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bb98439d-3a4a-4ac6-9bc8-b39b988d8d45"
      },
      "source": [
        "clusters.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lcl_id</th>\n",
              "      <th>cluster</th>\n",
              "      <th>train_test_split</th>\n",
              "      <th>num_clusters</th>\n",
              "      <th>cluster_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MAC000034</td>\n",
              "      <td>0.0</td>\n",
              "      <td>test</td>\n",
              "      <td>8</td>\n",
              "      <td>agglo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MAC004877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>test</td>\n",
              "      <td>8</td>\n",
              "      <td>agglo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MAC004954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>test</td>\n",
              "      <td>8</td>\n",
              "      <td>agglo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MAC004970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>test</td>\n",
              "      <td>8</td>\n",
              "      <td>agglo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MAC005198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>test</td>\n",
              "      <td>8</td>\n",
              "      <td>agglo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      lcl_id  cluster train_test_split  num_clusters cluster_type\n",
              "0  MAC000034      0.0             test             8        agglo\n",
              "1  MAC004877      0.0             test             8        agglo\n",
              "2  MAC004954      0.0             test             8        agglo\n",
              "3  MAC004970      0.0             test             8        agglo\n",
              "4  MAC005198      0.0             test             8        agglo"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qJFF57TVnTJ",
        "colab_type": "text"
      },
      "source": [
        "### **Utility Functions..**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbhxIK8nVlTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_clusters(df_train, df_test, test_period=\"2013-02-01\"):\n",
        "    forecast_dict = {}\n",
        "    test_global_fc = pd.DataFrame()\n",
        "    train_global_fc = pd.DataFrame()\n",
        "    clusters = df_train.groupby('cluster').count().index.to_list()\n",
        "    for cluster in clusters:\n",
        "        cluster_dict = {} \n",
        "        print(f\"\\nTraining cluster: {cluster}\") \n",
        "        print(\"---------------------------\")\n",
        "        df_train_cluster = df_train.query(f\"cluster=={cluster}\").copy()\n",
        "        df_test_cluster = df_test.query(f\"cluster=={cluster}\").copy()\n",
        "        model = TrainProphet(test_period)\n",
        "        model.fit(df_train_cluster)\n",
        "        model.evaluate_test_global_mape(df_test_cluster)\n",
        "        cluster_dict['model'] = model \n",
        "        forecast_dict[f'cluster_{cluster}']=cluster_dict\n",
        "        test_global_fc = pd.concat([test_global_fc, model.test_forecast])\n",
        "\n",
        "        train_forecast = df_train[['cluster','ds','y']].copy()\n",
        "        train_forecast['max_households'] = df_train['households_num'].max()\n",
        "        train_forecast = train_forecast.merge(model.forecast[['ds', 'yhat']], left_on='ds', right_on='ds')\n",
        "        train_forecast['y_global'] = train_forecast['y'] * train_forecast['max_households']\n",
        "        train_forecast['yhat_global'] = train_forecast['yhat'] * train_forecast['max_households']\n",
        "        train_global_fc = pd.concat([train_global_fc, train_forecast])\n",
        "\n",
        "    return forecast_dict, test_global_fc, train_global_fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEr7g172X0zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_timeseries(df, clusters_df, cluster_type, num_clusters):\n",
        "    clusters = clusters_df.query(f\"cluster_type=='{cluster_type}' and num_clusters=={num_clusters}\")\n",
        "    out_df = df.merge(clusters[['lcl_id','cluster']], left_on='lcl_id', right_on='lcl_id')\n",
        "    households_num = pd.DataFrame(out_df.groupby('cluster')['lcl_id'].nunique())\n",
        "    households_num.rename(columns={'lcl_id':'households_num'}, inplace=True)\n",
        "\n",
        "    timeseries = out_df.groupby(['cluster','ds']).mean().reset_index()\n",
        "    timeseries = timeseries.merge(households_num, left_on='cluster', right_on='cluster')\n",
        "    return timeseries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zV6MR_peDBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_cluster_forecast(df_train, df_test, cluster_type, clusters, cluster_list):\n",
        "    results_dict = {}\n",
        "    \n",
        "    for cluster in cluster_list:\n",
        "        cluster_forecast_dict = {}\n",
        "        print(f\"\\n ----------------------------------\")\n",
        "        print(f\"|Total number of clusters: {cluster}...   |\")\n",
        "        print(f\" ----------------------------------\")\n",
        "\n",
        "        train = get_timeseries(df_train, clusters, cluster_type=cluster_type, num_clusters=cluster)\n",
        "        test = get_timeseries(df_test, clusters, cluster_type=cluster_type, num_clusters=cluster)\n",
        "\n",
        "        model_dict, global_test, global_train = train_clusters(train, test)\n",
        "\n",
        "        cluster_forecast_dict['model'] = model_dict\n",
        "        cluster_forecast_dict['global_test'] = global_test\n",
        "        cluster_forecast_dict['global_train'] = global_train \n",
        "\n",
        "        results_dict[f\"num_clusters_{cluster}\"] = cluster_forecast_dict \n",
        "\n",
        "    return results_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kky74E1-V67I",
        "colab_type": "text"
      },
      "source": [
        "### **Training Forecasts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suydcguUftV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6006e891-df46-43e5-9c67-acef762d4a97"
      },
      "source": [
        "cluster_list = [2,3,4,5,6,7,8]\n",
        "agglo_results = train_cluster_forecast(df_train, df_test, 'agglo', clusters, cluster_list)\n",
        "som_results = train_cluster_forecast(df_train, df_test, 'som', clusters, cluster_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ----------------------------------\n",
            "|Total number of clusters: 2...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.790572916666669\n",
            "Test Mean Absolute Percentage Error: 8.23\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.77916666666666\n",
            "Test Mean Absolute Percentage Error: 29.25\n",
            " ----------------------------------\n",
            "|Total number of clusters: 3...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.569873511904763\n",
            "Test Mean Absolute Percentage Error: 64.62\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.77916666666666\n",
            "Test Mean Absolute Percentage Error: 156.81\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.447537202380951\n",
            "Test Mean Absolute Percentage Error: 8.110000000000001\n",
            " ----------------------------------\n",
            "|Total number of clusters: 4...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.77916666666666\n",
            "Test Mean Absolute Percentage Error: 156.81\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.647232142857149\n",
            "Test Mean Absolute Percentage Error: 52.38\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.447537202380951\n",
            "Test Mean Absolute Percentage Error: 8.110000000000001\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 79.13171875000015\n",
            "Test Mean Absolute Percentage Error: 72.17\n",
            " ----------------------------------\n",
            "|Total number of clusters: 5...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.647232142857149\n",
            "Test Mean Absolute Percentage Error: 52.38\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 14.201674107142859\n",
            "Test Mean Absolute Percentage Error: 27.939999999999998\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.447537202380951\n",
            "Test Mean Absolute Percentage Error: 8.110000000000001\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 79.13171875000015\n",
            "Test Mean Absolute Percentage Error: 239.78000000000003\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.132202380952364\n",
            "Test Mean Absolute Percentage Error: 27.560000000000002\n",
            " ----------------------------------\n",
            "|Total number of clusters: 6...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 14.201674107142859\n",
            "Test Mean Absolute Percentage Error: 27.939999999999998\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.132202380952364\n",
            "Test Mean Absolute Percentage Error: 163.72\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.447537202380951\n",
            "Test Mean Absolute Percentage Error: 8.110000000000001\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 79.13171875000015\n",
            "Test Mean Absolute Percentage Error: 57.79\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.232142857142842\n",
            "Test Mean Absolute Percentage Error: 26.479999999999997\n",
            "\n",
            "Training cluster: 5.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.893110119047597\n",
            "Test Mean Absolute Percentage Error: 68.35\n",
            " ----------------------------------\n",
            "|Total number of clusters: 7...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.132202380952364\n",
            "Test Mean Absolute Percentage Error: 163.72\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 79.13171875000015\n",
            "Test Mean Absolute Percentage Error: 57.79\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.447537202380951\n",
            "Test Mean Absolute Percentage Error: 8.110000000000001\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 15.594903273809537\n",
            "Test Mean Absolute Percentage Error: 53.22\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.232142857142842\n",
            "Test Mean Absolute Percentage Error: 26.479999999999997\n",
            "\n",
            "Training cluster: 5.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.893110119047597\n",
            "Test Mean Absolute Percentage Error: 68.35\n",
            "\n",
            "Training cluster: 6.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 1354133157166.448\n",
            "Test Mean Absolute Percentage Error: 100.8\n",
            " ----------------------------------\n",
            "|Total number of clusters: 8...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 79.13171875000015\n",
            "Test Mean Absolute Percentage Error: 57.79\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 11.302418154761911\n",
            "Test Mean Absolute Percentage Error: 60.6\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.447537202380951\n",
            "Test Mean Absolute Percentage Error: 8.110000000000001\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 15.594903273809537\n",
            "Test Mean Absolute Percentage Error: 53.22\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.232142857142842\n",
            "Test Mean Absolute Percentage Error: 71.32\n",
            "\n",
            "Training cluster: 5.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.893110119047597\n",
            "Test Mean Absolute Percentage Error: 68.35\n",
            "\n",
            "Training cluster: 6.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 1354133157166.448\n",
            "Test Mean Absolute Percentage Error: 100.8\n",
            "\n",
            "Training cluster: 7.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.861770833333335\n",
            "Test Mean Absolute Percentage Error: 77.81\n",
            " ----------------------------------\n",
            "|Total number of clusters: 2...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.874479166666674\n",
            "Test Mean Absolute Percentage Error: 9.24\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.475699404761915\n",
            "Test Mean Absolute Percentage Error: 13.01\n",
            " ----------------------------------\n",
            "|Total number of clusters: 3...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.89610119047621\n",
            "Test Mean Absolute Percentage Error: 18.01\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.769233630952371\n",
            "Test Mean Absolute Percentage Error: 9.16\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.361011904761908\n",
            "Test Mean Absolute Percentage Error: 8.9\n",
            " ----------------------------------\n",
            "|Total number of clusters: 4...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.408162202380947\n",
            "Test Mean Absolute Percentage Error: 11.74\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.713020833333331\n",
            "Test Mean Absolute Percentage Error: 9.51\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.521272321428574\n",
            "Test Mean Absolute Percentage Error: 9.29\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 67.34281994047618\n",
            "Test Mean Absolute Percentage Error: 55.510000000000005\n",
            " ----------------------------------\n",
            "|Total number of clusters: 5...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.670476190476199\n",
            "Test Mean Absolute Percentage Error: 16.05\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 78.54380208333343\n",
            "Test Mean Absolute Percentage Error: 59.74\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.401599702380938\n",
            "Test Mean Absolute Percentage Error: 10.27\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.524538690476184\n",
            "Test Mean Absolute Percentage Error: 9.78\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 6.989717261904765\n",
            "Test Mean Absolute Percentage Error: 7.79\n",
            " ----------------------------------\n",
            "|Total number of clusters: 6...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 13.610811011904783\n",
            "Test Mean Absolute Percentage Error: 12.4\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 78.54380208333343\n",
            "Test Mean Absolute Percentage Error: 59.74\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.903065476190479\n",
            "Test Mean Absolute Percentage Error: 10.08\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.114724702380949\n",
            "Test Mean Absolute Percentage Error: 12.6\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.292775297619036\n",
            "Test Mean Absolute Percentage Error: 11.97\n",
            "\n",
            "Training cluster: 5.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.006220238095233\n",
            "Test Mean Absolute Percentage Error: 7.7700000000000005\n",
            " ----------------------------------\n",
            "|Total number of clusters: 7...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.998898809523817\n",
            "Test Mean Absolute Percentage Error: 10.209999999999999\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 17.44555059523811\n",
            "Test Mean Absolute Percentage Error: 14.97\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.553638392857152\n",
            "Test Mean Absolute Percentage Error: 10.96\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.9734226190476\n",
            "Test Mean Absolute Percentage Error: 11.85\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.65594494047619\n",
            "Test Mean Absolute Percentage Error: 14.899999999999999\n",
            "\n",
            "Training cluster: 5.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 6.624040178571427\n",
            "Test Mean Absolute Percentage Error: 8.89\n",
            "\n",
            "Training cluster: 6.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 78.54380208333343\n",
            "Test Mean Absolute Percentage Error: 59.74\n",
            " ----------------------------------\n",
            "|Total number of clusters: 8...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 10.001964285714278\n",
            "Test Mean Absolute Percentage Error: 11.450000000000001\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 13.610811011904783\n",
            "Test Mean Absolute Percentage Error: 12.65\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.352113095238105\n",
            "Test Mean Absolute Percentage Error: 9.8\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.225111607142846\n",
            "Test Mean Absolute Percentage Error: 10.35\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.945193452380959\n",
            "Test Mean Absolute Percentage Error: 13.350000000000001\n",
            "\n",
            "Training cluster: 5.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 6.5765178571428535\n",
            "Test Mean Absolute Percentage Error: 8.64\n",
            "\n",
            "Training cluster: 6.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 104.86796875000003\n",
            "Test Mean Absolute Percentage Error: 65.56\n",
            "\n",
            "Training cluster: 7.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 25.760364583333367\n",
            "Test Mean Absolute Percentage Error: 36.08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSnnnoU4lqll",
        "colab_type": "text"
      },
      "source": [
        "### **Evaluate Forecast**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk1MHVS1l24b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5acf934a-ee49-47ae-b9d4-698211699aa3"
      },
      "source": [
        "train_global_results = agglo_results['num_clusters_2']['global_train'].groupby('ds')[['y_global','yhat_global']].sum()\n",
        "test_global_results = agglo_results['num_clusters_2']['global_test'].groupby('ds')[['y_global','yhat_global']].sum()\n",
        "\n",
        "train_global_mape = np.round(np.mean(np.abs(train_global_results['yhat_global']/train_global_results['y_global']-1)),4)*100\n",
        "test_global_mape = np.round(np.mean(np.abs(test_global_results['yhat_global']/test_global_results['y_global']-1)),4)*100\n",
        "\n",
        "print(train_global_mape, test_global_mape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.660000000000001 9.180000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GonLw8Vnl2yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_results(results_dict):\n",
        "    for num_clusters in results_dict.keys():\n",
        "        train_results = results_dict[num_clusters]['global_train'].groupby('ds')[['y_global','yhat_global']].sum()\n",
        "        test_results = results_dict[num_clusters]['global_test'].groupby('ds')[['y_global', 'yhat_global']].sum() \n",
        "\n",
        "        train_global_mape = np.round(np.mean(np.abs(train_results['yhat_global']/train_results['y_global']-1)),4)*100\n",
        "        test_global_mape = np.round(np.mean(np.abs(test_results['yhat_global']/test_results['y_global']-1)),4)*100\n",
        "        results_dict[num_clusters]['train_global_mape'] = train_global_mape\n",
        "        results_dict[num_clusters]['test_global_mape'] = test_global_mape\n",
        "\n",
        "        print(f\"Number of Clusters = {num_clusters}: Train Global MAPE: {train_global_mape}. Test Global MAPE: {test_global_mape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIAzzlGLl2nO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b56d7b4b-b82a-4968-9b5e-46ad1b9c9b35"
      },
      "source": [
        "evaluate_results(agglo_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Clusters = num_clusters_2: Train Global MAPE: 6.660000000000001. Test Global MAPE: 9.180000000000001\n",
            "Number of Clusters = num_clusters_3: Train Global MAPE: 6.569999999999999. Test Global MAPE: 71.78\n",
            "Number of Clusters = num_clusters_4: Train Global MAPE: 12.22. Test Global MAPE: 74.11\n",
            "Number of Clusters = num_clusters_5: Train Global MAPE: 9.27. Test Global MAPE: 77.21000000000001\n",
            "Number of Clusters = num_clusters_6: Train Global MAPE: 8.64. Test Global MAPE: 58.13\n",
            "Number of Clusters = num_clusters_7: Train Global MAPE: 9.06. Test Global MAPE: 57.52\n",
            "Number of Clusters = num_clusters_8: Train Global MAPE: 8.35. Test Global MAPE: 34.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LulOnGtml12T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6b8e6837-2a89-4cf6-c724-aff513572a35"
      },
      "source": [
        "evaluate_results(som_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Clusters = num_clusters_2: Train Global MAPE: 6.800000000000001. Test Global MAPE: 8.89\n",
            "Number of Clusters = num_clusters_3: Train Global MAPE: 6.77. Test Global MAPE: 8.82\n",
            "Number of Clusters = num_clusters_4: Train Global MAPE: 11.49. Test Global MAPE: 7.7299999999999995\n",
            "Number of Clusters = num_clusters_5: Train Global MAPE: 10.22. Test Global MAPE: 7.55\n",
            "Number of Clusters = num_clusters_6: Train Global MAPE: 8.92. Test Global MAPE: 7.66\n",
            "Number of Clusters = num_clusters_7: Train Global MAPE: 8.67. Test Global MAPE: 7.8100000000000005\n",
            "Number of Clusters = num_clusters_8: Train Global MAPE: 9.48. Test Global MAPE: 7.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snNHe8YWqkk6",
        "colab_type": "text"
      },
      "source": [
        "### **Saving results to BigQuery**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3nw3_BCqnl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "243c94e6-d861-49d7-9bc2-205c0c81d71e"
      },
      "source": [
        "agglo_results['num_clusters_2']['global_test']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cluster</th>\n",
              "      <th>ds</th>\n",
              "      <th>y</th>\n",
              "      <th>air_temperature</th>\n",
              "      <th>households_num</th>\n",
              "      <th>max_households</th>\n",
              "      <th>yhat</th>\n",
              "      <th>y_global</th>\n",
              "      <th>yhat_global</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2013-02-01 00:00:00</td>\n",
              "      <td>0.187505</td>\n",
              "      <td>7.9</td>\n",
              "      <td>969</td>\n",
              "      <td>969</td>\n",
              "      <td>0.198027</td>\n",
              "      <td>181.692505</td>\n",
              "      <td>191.888040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2013-02-01 00:30:00</td>\n",
              "      <td>0.166509</td>\n",
              "      <td>7.9</td>\n",
              "      <td>969</td>\n",
              "      <td>969</td>\n",
              "      <td>0.181534</td>\n",
              "      <td>161.347509</td>\n",
              "      <td>175.906466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2013-02-01 01:00:00</td>\n",
              "      <td>0.143679</td>\n",
              "      <td>7.7</td>\n",
              "      <td>969</td>\n",
              "      <td>969</td>\n",
              "      <td>0.165928</td>\n",
              "      <td>139.224679</td>\n",
              "      <td>160.783830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2013-02-01 01:30:00</td>\n",
              "      <td>0.127416</td>\n",
              "      <td>7.7</td>\n",
              "      <td>969</td>\n",
              "      <td>969</td>\n",
              "      <td>0.150054</td>\n",
              "      <td>123.466416</td>\n",
              "      <td>145.402075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2013-02-01 02:00:00</td>\n",
              "      <td>0.115903</td>\n",
              "      <td>7.8</td>\n",
              "      <td>969</td>\n",
              "      <td>969</td>\n",
              "      <td>0.134279</td>\n",
              "      <td>112.309903</td>\n",
              "      <td>130.116335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1339</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2013-02-28 21:30:00</td>\n",
              "      <td>0.921581</td>\n",
              "      <td>4.0</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>1.155914</td>\n",
              "      <td>28.569000</td>\n",
              "      <td>35.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1340</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2013-02-28 22:00:00</td>\n",
              "      <td>0.983355</td>\n",
              "      <td>3.5</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>1.103999</td>\n",
              "      <td>30.484000</td>\n",
              "      <td>34.223980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1341</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2013-02-28 22:30:00</td>\n",
              "      <td>0.887387</td>\n",
              "      <td>3.5</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>1.039425</td>\n",
              "      <td>27.509000</td>\n",
              "      <td>32.222166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1342</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2013-02-28 23:00:00</td>\n",
              "      <td>0.832645</td>\n",
              "      <td>2.7</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>0.982447</td>\n",
              "      <td>25.812000</td>\n",
              "      <td>30.455861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1343</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2013-02-28 23:30:00</td>\n",
              "      <td>0.753484</td>\n",
              "      <td>2.7</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>0.915016</td>\n",
              "      <td>23.358000</td>\n",
              "      <td>28.365486</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2688 rows √ó 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cluster                  ds         y  ...      yhat    y_global  yhat_global\n",
              "0         0.0 2013-02-01 00:00:00  0.187505  ...  0.198027  181.692505   191.888040\n",
              "1         0.0 2013-02-01 00:30:00  0.166509  ...  0.181534  161.347509   175.906466\n",
              "2         0.0 2013-02-01 01:00:00  0.143679  ...  0.165928  139.224679   160.783830\n",
              "3         0.0 2013-02-01 01:30:00  0.127416  ...  0.150054  123.466416   145.402075\n",
              "4         0.0 2013-02-01 02:00:00  0.115903  ...  0.134279  112.309903   130.116335\n",
              "...       ...                 ...       ...  ...       ...         ...          ...\n",
              "1339      1.0 2013-02-28 21:30:00  0.921581  ...  1.155914   28.569000    35.833333\n",
              "1340      1.0 2013-02-28 22:00:00  0.983355  ...  1.103999   30.484000    34.223980\n",
              "1341      1.0 2013-02-28 22:30:00  0.887387  ...  1.039425   27.509000    32.222166\n",
              "1342      1.0 2013-02-28 23:00:00  0.832645  ...  0.982447   25.812000    30.455861\n",
              "1343      1.0 2013-02-28 23:30:00  0.753484  ...  0.915016   23.358000    28.365486\n",
              "\n",
              "[2688 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUbvd7hWqzue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec49fb64-5898-4ade-8263-966f267e781d"
      },
      "source": [
        "for cluster in agglo_results:\n",
        "    global_train = agglo_results[cluster]['global_train']\n",
        "    global_test = agglo_results[cluster]['global_test']\n",
        "\n",
        "    global_train['cluster_type'] = \"agglo\"\n",
        "    global_train['num_clusters'] = cluster \n",
        "    global_test['cluster_type'] = \"agglo\"\n",
        "    global_test['num_clusters'] = cluster\n",
        "\n",
        "    output_to_bq(global_train, table_id='20200739.train_results')\n",
        "    output_to_bq(global_test, table_id='20200739.test_results')\n",
        "    print(f\"{cluster} results uploaded to BQ!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "23040 out of 23040 rows loaded.\n",
            "\n",
            "1it [00:09,  9.53s/it]\n",
            "\n",
            "2688 out of 2688 rows loaded.\n",
            "1it [00:03,  3.13s/it]\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_2 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pandas_gbq.gbq:\r51840 out of 51840 rows loaded.\n",
            "\n",
            "1it [00:05,  5.56s/it]\n",
            "\n",
            "4032 out of 4032 rows loaded.\n",
            "1it [00:06,  6.03s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_3 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "92160 out of 92160 rows loaded.\n",
            "\n",
            "1it [00:30, 30.35s/it]\n",
            "\n",
            "5376 out of 5376 rows loaded.\n",
            "\n",
            "1it [00:09,  9.15s/it]\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_4 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pandas_gbq.gbq:\r144000 out of 144000 rows loaded.\n",
            "\n",
            "1it [00:11, 11.29s/it]\n",
            "\n",
            "6720 out of 6720 rows loaded.\n",
            "\n",
            "1it [00:06,  6.26s/it]\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_5 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pandas_gbq.gbq:\r207360 out of 207360 rows loaded.\n",
            "\n",
            "1it [00:14, 14.86s/it]\n",
            "\n",
            "8064 out of 8064 rows loaded.\n",
            "\n",
            "1it [00:08,  8.93s/it]\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_6 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pandas_gbq.gbq:\r282240 out of 282240 rows loaded.\n",
            "\n",
            "1it [00:18, 18.65s/it]\n",
            "\n",
            "9408 out of 9408 rows loaded.\n",
            "\n",
            "1it [00:03,  3.69s/it]\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_7 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pandas_gbq.gbq:\r368640 out of 368640 rows loaded.\n",
            "\n",
            "1it [00:23, 23.29s/it]\n",
            "\n",
            "10752 out of 10752 rows loaded.\n",
            "\n",
            "1it [00:05,  5.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_8 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJg9YkBLrXy4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a4d95290-a612-4025-aa2e-4e73fc92647d"
      },
      "source": [
        "for cluster in som_results:\n",
        "    global_train = som_results[cluster]['global_train']\n",
        "    global_test = som_results[cluster]['global_test']\n",
        "\n",
        "    global_train['cluster_type'] = \"som\"\n",
        "    global_train['num_clusters'] = cluster \n",
        "    global_test['cluster_type'] = \"som\"\n",
        "    global_test['num_clusters'] = cluster\n",
        "\n",
        "    output_to_bq(global_train, table_id='20200739.train_results')\n",
        "    output_to_bq(global_test, table_id='20200739.test_results')\n",
        "    print(f\"{cluster} results uploaded to BQ!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "23040 out of 23040 rows loaded.\n",
            "\n",
            "1it [00:06,  6.20s/it]\n",
            "\n",
            "2688 out of 2688 rows loaded.\n",
            "1it [00:02,  2.86s/it]\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_2 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pandas_gbq.gbq:\r51840 out of 51840 rows loaded.\n",
            "\n",
            "1it [00:06,  6.21s/it]\n",
            "\n",
            "4032 out of 4032 rows loaded.\n",
            "1it [01:14, 74.73s/it]\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_3 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pandas_gbq.gbq:\r92160 out of 92160 rows loaded.\n",
            "\n",
            "1it [00:12, 12.72s/it]\n",
            "\n",
            "5376 out of 5376 rows loaded.\n",
            "\n",
            "1it [00:03,  3.18s/it]\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_4 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pandas_gbq.gbq:\r144000 out of 144000 rows loaded.\n",
            "\n",
            "1it [00:15, 15.02s/it]\n",
            "\n",
            "6720 out of 6720 rows loaded.\n",
            "\n",
            "1it [00:03,  3.89s/it]\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_5 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pandas_gbq.gbq:\r207360 out of 207360 rows loaded.\n",
            "\n",
            "1it [00:15, 15.21s/it]\n",
            "\n",
            "8064 out of 8064 rows loaded.\n",
            "\n",
            "1it [00:04,  4.43s/it]\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_6 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pandas_gbq.gbq:\r282240 out of 282240 rows loaded.\n",
            "\n",
            "1it [00:17, 17.13s/it]\n",
            "\n",
            "9408 out of 9408 rows loaded.\n",
            "\n",
            "1it [00:07,  7.48s/it]\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_7 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pandas_gbq.gbq:\r368640 out of 368640 rows loaded.\n",
            "\n",
            "1it [00:37, 37.04s/it]\n",
            "\n",
            "10752 out of 10752 rows loaded.\n",
            "\n",
            "1it [00:04,  4.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_clusters_8 results uploaded to BQ!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oVY5TE3t26C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}