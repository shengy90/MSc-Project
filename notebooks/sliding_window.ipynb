{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8th August",
      "provenance": [],
      "collapsed_sections": [
        "svsqrk45tb_B",
        "G4sbx8kLH89t",
        "1hmNPC7g-R9E"
      ],
      "toc_visible": true,
      "mount_file_id": "1XQiLyjIhVdgtFhuzVLHo5QTOzMLa85lV",
      "authorship_tag": "ABX9TyOHqrzRBVPPv4U94R0uFQ+o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shengy90/MSc-Project/blob/master/notebooks/sliding_window.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svsqrk45tb_B",
        "colab_type": "text"
      },
      "source": [
        "# **1Ô∏è‚É£ Setup Notebook üíª**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eJpHGVpGuji",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### **Authenticate with BigQuery ‚òÅÔ∏è**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkaOt64QmU90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade google-cloud-bigquery[bqstorage,pandas]\n",
        "!pip install --upgrade pandas-gbq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6y1_cKZGJ1C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16bf52ed-eadc-4ae7-f9a0-a32999dc4e89"
      },
      "source": [
        "import google.auth\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import bigquery_storage_v1beta1\n",
        "\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authenticated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts6qMG3PGlUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "credentials, your_project_id = google.auth.default(scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
        "your_project_id = 'machine-learning-msc'\n",
        "# Make clients.\n",
        "bqclient = bigquery.Client(\n",
        "    credentials=credentials,\n",
        "    project=your_project_id\n",
        "    )\n",
        "bqstorageclient = bigquery_storage_v1beta1.BigQueryStorageClient(\n",
        "    credentials=credentials\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv_j8ZER6G6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query_string = \"\"\"\n",
        "SELECT\n",
        "COUNT(*) AS test\n",
        "FROM `machine-learning-msc.low_carbon_london.household_consumption_daily_agg` \n",
        "\"\"\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuQx-I0bAIju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_query_results(query_string, bqclient=bqclient, bqstorateclient=bqstorageclient):\n",
        "    df = bqclient.query(query_string).result().to_dataframe(bqstorage_client=bqstorageclient)\n",
        "    return df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tKDHCl56H2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "7fe0c1fb-6ae5-489a-c727-dec0e3720561"
      },
      "source": [
        "df = download_query_results(query_string, bqclient, bqstorageclient)\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14841792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       test\n",
              "0  14841792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlyM_RE6rf5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas_gbq\n",
        "def output_to_bq(forecast, table_id, project_id='machine-learning-msc'):\n",
        "    pandas_gbq.to_gbq(forecast, table_id, project_id=project_id, if_exists='append')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4sbx8kLH89t",
        "colab_type": "text"
      },
      "source": [
        "### **Importing Libraries‚è¨**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmVtQy38Ozr6",
        "colab_type": "text"
      },
      "source": [
        "##### Standard Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0JiDvCG3U4F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "43a7d6f6-4d0c-4540-8644-151ed6323771"
      },
      "source": [
        "!pip install fbprophet\n",
        "!pip install MiniSom"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fbprophet in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: Cython>=0.22 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (0.29.21)\n",
            "Requirement already satisfied: cmdstanpy==0.4 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (0.4.0)\n",
            "Requirement already satisfied: pystan>=2.14 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (2.19.1.1)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (1.0.5)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (3.2.2)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (0.0.9)\n",
            "Requirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (2.2.1)\n",
            "Requirement already satisfied: holidays>=0.9.5 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (0.9.12)\n",
            "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->fbprophet) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->fbprophet) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->fbprophet) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->fbprophet) (0.10.0)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.6/dist-packages (from LunarCalendar>=0.0.9->fbprophet) (3.7.7.1)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.6 in /usr/local/lib/python3.6/dist-packages (from convertdate>=2.1.2->fbprophet) (0.3.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from holidays>=0.9.5->fbprophet) (1.15.0)\n",
            "Collecting MiniSom\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/10/a1c1621000d5ca00c41695689551c1a4d6d245d7bbf099d81e067da3e8f2/MiniSom-2.2.6.tar.gz\n",
            "Building wheels for collected packages: MiniSom\n",
            "  Building wheel for MiniSom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for MiniSom: filename=MiniSom-2.2.6-cp36-none-any.whl size=8525 sha256=ffbcf4ffb245744ccb447b39b0810513088b2662045047ff672b9642be1799a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/c6/01/330066e36e1f7c826c96f656f9185822cfcdef0591315949ea\n",
            "Successfully built MiniSom\n",
            "Installing collected packages: MiniSom\n",
            "Successfully installed MiniSom-2.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr9vUfxAICRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ec2cf6c8-882c-4245-b93b-9f56e3199744"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import random\n",
        "import datetime as dt\n",
        "\n",
        "from minisom import MiniSom\n",
        "from tqdm import tqdm\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        " \n",
        "sns.set()\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQE0xrL4JT4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas_gbq\n",
        "def output_to_bq(forecast, table_id, project_id='machine-learning-msc'):\n",
        "    pandas_gbq.to_gbq(forecast, table_id, project_id=project_id, if_exists='append')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq2GQCXqO2ZD",
        "colab_type": "text"
      },
      "source": [
        "##### Import Github Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtzIWQvBPESj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d2d4e749-2714-41d1-9ab8-7ccae13ba3b0"
      },
      "source": [
        "%cd /content\n",
        "!rm -rf mscproj\n",
        "!git clone https://github.com/shengy90/MSc-Project mscproj\n",
        "!git pull\n",
        "%cd /content/mscproj/\n",
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'mscproj'...\n",
            "remote: Enumerating objects: 155, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 516 (delta 101), reused 100 (delta 53), pack-reused 361\u001b[K\n",
            "Receiving objects: 100% (516/516), 12.72 MiB | 29.01 MiB/s, done.\n",
            "Resolving deltas: 100% (299/299), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "/content/mscproj\n",
            "bin\t     __init__.py  notebooks  requirements.txt  sql\n",
            "definitions  Makefile\t  README.md  run.py\t       src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnq6lOTUXbat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload \n",
        "%autoreload 2 \n",
        "from src.train_prophet import TrainProphet\n",
        "from src.train_clusters import TrainClusters\n",
        "from src.train_clusters import Normaliser\n",
        "from src.train_sliding_window import train_som, train_baseline, train_som_forecasts, evaluate_results, generate_query_strings"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hmNPC7g-R9E",
        "colab_type": "text"
      },
      "source": [
        "# **2Ô∏è‚É£ Sliding Window Protocol**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JBFOy2Us_Vg",
        "colab_type": "text"
      },
      "source": [
        "## **Create Sliding Window Protocol**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu5_qqWZmNJz",
        "colab_type": "text"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwUBq7xZrppf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_results(df, train_test_split, model_name, num_clusters, start_date, end_date, eval_date, model_date):\n",
        "    save_df = df.copy()\n",
        "    save_df['model_date'] = model_date\n",
        "    save_df['start_date'] = start_date\n",
        "    save_df['end_date'] = end_date\n",
        "    save_df['eval_date'] = eval_date             \n",
        "    save_df['model'] = model_name\n",
        "    save_df['train_test_split'] = train_test_split\n",
        "    save_df['num_clusters'] = 5\n",
        "    output_to_bq(save_df, 'sliding_window.results')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAAS3FNAlQDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_forecast(start_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\").date()\n",
        "\n",
        "    end_date = start_date + relativedelta(months=4)\n",
        "    eval_date = start_date + relativedelta(months=3)\n",
        "    start_date = start_date.strftime(\"%Y-%m-%d\")\n",
        "    end_date = end_date.strftime(\"%Y-%m-%d\")\n",
        "    eval_date = eval_date.strftime(\"%Y-%m-%d\")\n",
        "    som_query_string, ts_query_string= generate_query_strings(start_date, end_date)\n",
        "\n",
        "    print(f\"\\nDownloading data for periods: {start_date} -> {end_date}\")\n",
        "    som_df = download_query_results(som_query_string, bqclient, bqstorageclient)\n",
        "    ts_df = download_query_results(ts_query_string, bqclient, bqstorageclient)\n",
        "    ts_df['ds'] = ts_df['ds'].dt.tz_localize(None)\n",
        "    \n",
        "    print(f\"Training SOM Clusters.....\")\n",
        "    som_clusters = train_som(som_df)\n",
        "    print(f\"Training Baseline Model.....\")\n",
        "    baseline_model = train_baseline(ts_df, som_clusters, eval_date)\n",
        "    print(f\"Training SOM Forecasts.....\")\n",
        "    som_model, som_train_global, som_test_global = train_som_forecasts(ts_df, som_clusters, eval_date)\n",
        "    \n",
        "    print(f\"\\nEvaluating Baseline...\")\n",
        "    evaluate_results(baseline_model.train_global, baseline_model.test_global)\n",
        "    print(f\"\\nEvaluating SOM...\")\n",
        "    evaluate_results(som_train_global, som_test_global)\n",
        "\n",
        "    print(f\"Uploading results to BigQuery...\")\n",
        "    save_results(baseline_model.train_global, \"train\", \"baseline\", 1, start_date, end_date, eval_date, '2020-08-09')\n",
        "    save_results(baseline_model.test_global, \"test\", \"baseline\", 1, start_date, end_date, eval_date, '2020-08-09')\n",
        "    save_results(som_train_global, \"train\", \"som_clusters\", 5, start_date, end_date, eval_date, '2020-08-09')\n",
        "    save_results(som_test_global, \"test\", \"som_clusters\", 5, start_date, end_date, eval_date, '2020-08-09')\n",
        "\n",
        "    print(f\"\\nFinished Training and Evaluation for periods: {start_date} -> {end_date}!\\n\")\n",
        "    print(\"--------------------------------------------------------------------------------\")\n",
        "\n",
        "    return som_clusters, baseline_model, som_train_global, som_test_global"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o32PbGqUmOqo",
        "colab_type": "text"
      },
      "source": [
        "### Forecasts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geHDoTHsmP3X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8d7d3ef-13ca-47c4-eb81-84120c193687"
      },
      "source": [
        "start_dates = ['2012-11-01', '2012-12-01', '2013-01-01', '2013-02-01']\n",
        "\n",
        "for start_date in start_dates:\n",
        "    som_clusters, baseline_model, som_train_global, som_test_global = train_forecast(start_date)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading data for periods: 2012-11-01 -> 2013-03-01\n",
            "Training SOM Clusters.....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 19.8415756779928\n",
            "Training Baseline Model.....\n",
            "Training SOM Forecasts.....\n",
            "\n",
            "Evaluating Baseline...\n",
            "Train global MAPE: 7.4399999999999995. Test global MAPE: 8.88.\n",
            "\n",
            "Evaluating SOM...\n",
            "Train global MAPE: 7.42. Test global MAPE: 7.55.\n",
            "Uploading results to BigQuery...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1344 out of 1344 rows loaded.\n",
            "1it [00:02,  2.28s/it]\n",
            "\n",
            "1344 out of 1344 rows loaded.\n",
            "1it [00:02,  2.95s/it]\n",
            "\n",
            "6720 out of 6720 rows loaded.\n",
            "\n",
            "1it [00:03,  3.56s/it]\n",
            "\n",
            "6720 out of 6720 rows loaded.\n",
            "\n",
            "1it [00:02,  2.33s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Finished Training and Evaluation for periods: 2012-11-01 -> 2013-03-01!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Downloading data for periods: 2012-12-01 -> 2013-04-01\n",
            "Training SOM Clusters.....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 19.75592700883923\n",
            "Training Baseline Model.....\n",
            "Training SOM Forecasts.....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1488 out of 1488 rows loaded.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating Baseline...\n",
            "Train global MAPE: 8.290000000000001. Test global MAPE: 9.120000000000001.\n",
            "\n",
            "Evaluating SOM...\n",
            "Train global MAPE: 8.44. Test global MAPE: 8.07.\n",
            "Uploading results to BigQuery...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:02,  2.42s/it]\n",
            "\n",
            "1488 out of 1488 rows loaded.\n",
            "1it [00:02,  2.44s/it]\n",
            "\n",
            "7440 out of 7440 rows loaded.\n",
            "\n",
            "1it [00:02,  2.91s/it]\n",
            "\n",
            "7440 out of 7440 rows loaded.\n",
            "\n",
            "1it [00:04,  4.32s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Finished Training and Evaluation for periods: 2012-12-01 -> 2013-04-01!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Downloading data for periods: 2013-01-01 -> 2013-05-01\n",
            "Training SOM Clusters.....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 20.26105510270428\n",
            "Training Baseline Model.....\n",
            "Training SOM Forecasts.....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1440 out of 1440 rows loaded.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating Baseline...\n",
            "Train global MAPE: 13.669999999999998. Test global MAPE: 13.020000000000001.\n",
            "\n",
            "Evaluating SOM...\n",
            "Train global MAPE: 14.04. Test global MAPE: 12.75.\n",
            "Uploading results to BigQuery...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:02,  2.94s/it]\n",
            "\n",
            "1440 out of 1440 rows loaded.\n",
            "1it [00:02,  2.74s/it]\n",
            "\n",
            "7200 out of 7200 rows loaded.\n",
            "\n",
            "1it [00:03,  3.70s/it]\n",
            "\n",
            "7200 out of 7200 rows loaded.\n",
            "\n",
            "1it [00:03,  3.92s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Finished Training and Evaluation for periods: 2013-01-01 -> 2013-05-01!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Downloading data for periods: 2013-02-01 -> 2013-06-01\n",
            "Training SOM Clusters.....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 21.25172153350484\n",
            "Training Baseline Model.....\n",
            "Training SOM Forecasts.....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1488 out of 1488 rows loaded.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating Baseline...\n",
            "Train global MAPE: 16.939999999999998. Test global MAPE: 17.65.\n",
            "\n",
            "Evaluating SOM...\n",
            "Train global MAPE: 19.259999999999998. Test global MAPE: 21.18.\n",
            "Uploading results to BigQuery...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:01,  1.96s/it]\n",
            "\n",
            "1488 out of 1488 rows loaded.\n",
            "1it [00:05,  5.06s/it]\n",
            "\n",
            "7440 out of 7440 rows loaded.\n",
            "\n",
            "1it [00:04,  4.54s/it]\n",
            "\n",
            "7440 out of 7440 rows loaded.\n",
            "\n",
            "1it [00:02,  2.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Finished Training and Evaluation for periods: 2013-02-01 -> 2013-06-01!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ex7ZrdP0SQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60jY92LZ8bmI",
        "colab_type": "text"
      },
      "source": [
        "# 3Ô∏è‚É£ **Evaluating Sliding Window Performance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iIAsKt19ZYI",
        "colab_type": "text"
      },
      "source": [
        "##### **Get Sliding Window Results from BQ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h0fk0MY89s-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc df_results --use_bqstorage_api\n",
        "WITH stg1 AS (\n",
        "SELECT \n",
        "CAST(TIMESTAMP_TRUNC(ds, MONTH) AS DATE) AS month,\n",
        "* EXCEPT(cluster),\n",
        "CAST(IF(model = 'baseline', 1, cluster) AS STRING) AS cluster\n",
        "FROM `machine-learning-msc.sliding_window.results`\n",
        "WHERE model_date = '2020-08-09' AND num_clusters = 5\n",
        ")\n",
        "\n",
        "SELECT \n",
        "*,\n",
        "ROW_NUMBER() OVER (PARTITION BY model, train_test_split, cluster ORDER BY ds ASC) AS row_num\n",
        "FROM stg1\n",
        "ORDER BY model, train_test_split, cluster, ds ASC"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEwQyhiq92SI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_results['ds'] = df_results['ds'].dt.tz_localize(None) # remove timezones \n",
        "\n",
        "df_baseline_train = df_results.query(\"model=='baseline' and train_test_split=='train'\").copy()\n",
        "df_baseline_test = df_results.query(\"model=='baseline' and train_test_split=='test'\").copy()\n",
        "df_som_train = df_results.query(\"model=='som_clusters' and train_test_split=='train'\").copy()\n",
        "df_som_test = df_results.query(\"model=='som_clusters' and train_test_split=='test'\").copy()"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL5sRVc295gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _agg_results(df, monthly):\n",
        "    if monthly==True:\n",
        "        aggcol = 'month'\n",
        "    else:\n",
        "        aggcol = 'ds'\n",
        "\n",
        "    agg = df.groupby(aggcol).sum()\n",
        "    agg.reset_index(inplace=True)\n",
        "    agg = agg[[aggcol, 'y_global', 'yhat_global']]\n",
        "    agg['abs_perc_err'] = np.round(np.abs(agg['yhat_global']/agg['y_global']-1),6)*100\n",
        "    return agg\n",
        "\n",
        "def evaluate_forecast(df, monthly=None):\n",
        "    forecasts = _agg_results(df, monthly)\n",
        "\n",
        "    if monthly is None:\n",
        "        print(f\"Global Mean Average Percentage Error: {np.mean(forecasts['abs_perc_err'])}\")\n",
        "    results = forecasts\n",
        "    return results"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jca0nrhEG2Ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_results(idx_name, df1, df2, df1_name, df2_name, first=None):\n",
        "    if first == True:\n",
        "        df1 = df1[[idx_name, 'abs_perc_err']].copy()\n",
        "        df1.rename(columns={'abs_perc_err':f\"{df1_name}_APE\"}, inplace=True)\n",
        "    df2 = df2[[idx_name, 'abs_perc_err']].copy()\n",
        "    df2.rename(columns={'abs_perc_err':f\"{df2_name}_APE\"}, inplace=True)\n",
        "\n",
        "    out_df = df1.merge(df2, left_on=idx_name, right_on=idx_name)\n",
        "    return out_df"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpF5pt4T-VvB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "aac188a6-ffbb-4016-e1ab-19ef419adbdf"
      },
      "source": [
        "print(\"\\nBaseline Train:\")\n",
        "x = evaluate_forecast(df_baseline_train)\n",
        "print(\"\\nBaseline Test:\")\n",
        "x = evaluate_forecast(df_baseline_test)\n",
        "print(\"\\nSOM Train:\")\n",
        "x = evaluate_forecast(df_som_train)\n",
        "print(\"\\nSOM Test:\")\n",
        "x = evaluate_forecast(df_som_test)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline Train:\n",
            "Global Mean Average Percentage Error: 9.575817505447196\n",
            "\n",
            "Baseline Test:\n",
            "Global Mean Average Percentage Error: 9.952238428017255\n",
            "\n",
            "SOM Train:\n",
            "Global Mean Average Percentage Error: 9.840680544188736\n",
            "\n",
            "SOM Test:\n",
            "Global Mean Average Percentage Error: 9.936238656533986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX3waLC-D-RG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basetrain = evaluate_forecast(df_baseline_train, monthly=True)\n",
        "basetest = evaluate_forecast(df_baseline_test, monthly=True)\n",
        "somtrain = evaluate_forecast(df_som_train, monthly=True)\n",
        "somtest = evaluate_forecast(df_som_test, monthly=True)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdvhzaNDFZAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monthly_ape = combine_results('month', basetrain, basetest, 'base_train', 'base_test', first=True)\n",
        "monthly_ape = combine_results('month', monthly_ape, somtrain, None, 'som_train')\n",
        "monthly_ape = combine_results('month', monthly_ape, somtest, None, 'som_test')"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9O4tahjGdO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "4ff8daad-ace3-4c81-972b-7d5bafa07cee"
      },
      "source": [
        "monthly_ape"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>base_train_APE</th>\n",
              "      <th>base_test_APE</th>\n",
              "      <th>som_train_APE</th>\n",
              "      <th>som_test_APE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-02-01</td>\n",
              "      <td>2.0544</td>\n",
              "      <td>1.5996</td>\n",
              "      <td>1.9770</td>\n",
              "      <td>0.1182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-03-01</td>\n",
              "      <td>3.7710</td>\n",
              "      <td>3.4763</td>\n",
              "      <td>4.2418</td>\n",
              "      <td>2.7302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-04-01</td>\n",
              "      <td>7.4952</td>\n",
              "      <td>5.9928</td>\n",
              "      <td>7.9079</td>\n",
              "      <td>5.5975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-05-01</td>\n",
              "      <td>15.7664</td>\n",
              "      <td>16.3137</td>\n",
              "      <td>17.4087</td>\n",
              "      <td>19.4474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-06-01</td>\n",
              "      <td>1.1297</td>\n",
              "      <td>0.7920</td>\n",
              "      <td>0.6504</td>\n",
              "      <td>0.0097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2013-07-01</td>\n",
              "      <td>3.7439</td>\n",
              "      <td>4.1796</td>\n",
              "      <td>4.1148</td>\n",
              "      <td>6.0481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2013-08-01</td>\n",
              "      <td>0.6945</td>\n",
              "      <td>0.1291</td>\n",
              "      <td>0.3574</td>\n",
              "      <td>0.4330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2013-09-01</td>\n",
              "      <td>5.7219</td>\n",
              "      <td>5.9296</td>\n",
              "      <td>5.7095</td>\n",
              "      <td>5.7272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2013-10-01</td>\n",
              "      <td>6.1696</td>\n",
              "      <td>5.7002</td>\n",
              "      <td>5.9388</td>\n",
              "      <td>5.5161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2013-11-01</td>\n",
              "      <td>8.4111</td>\n",
              "      <td>8.5694</td>\n",
              "      <td>8.1120</td>\n",
              "      <td>8.7072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2013-12-01</td>\n",
              "      <td>5.3336</td>\n",
              "      <td>4.3595</td>\n",
              "      <td>5.9368</td>\n",
              "      <td>4.5482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2014-01-01</td>\n",
              "      <td>0.4051</td>\n",
              "      <td>1.1686</td>\n",
              "      <td>0.4203</td>\n",
              "      <td>0.9315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2014-02-01</td>\n",
              "      <td>4.2401</td>\n",
              "      <td>2.0401</td>\n",
              "      <td>4.0348</td>\n",
              "      <td>1.5104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         month  base_train_APE  base_test_APE  som_train_APE  som_test_APE\n",
              "0   2013-02-01          2.0544         1.5996         1.9770        0.1182\n",
              "1   2013-03-01          3.7710         3.4763         4.2418        2.7302\n",
              "2   2013-04-01          7.4952         5.9928         7.9079        5.5975\n",
              "3   2013-05-01         15.7664        16.3137        17.4087       19.4474\n",
              "4   2013-06-01          1.1297         0.7920         0.6504        0.0097\n",
              "5   2013-07-01          3.7439         4.1796         4.1148        6.0481\n",
              "6   2013-08-01          0.6945         0.1291         0.3574        0.4330\n",
              "7   2013-09-01          5.7219         5.9296         5.7095        5.7272\n",
              "8   2013-10-01          6.1696         5.7002         5.9388        5.5161\n",
              "9   2013-11-01          8.4111         8.5694         8.1120        8.7072\n",
              "10  2013-12-01          5.3336         4.3595         5.9368        4.5482\n",
              "11  2014-01-01          0.4051         1.1686         0.4203        0.9315\n",
              "12  2014-02-01          4.2401         2.0401         4.0348        1.5104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmADqagRIK2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}